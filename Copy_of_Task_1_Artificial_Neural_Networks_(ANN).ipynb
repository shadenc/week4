{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cda1ba95",
      "metadata": {
        "id": "cda1ba95"
      },
      "source": [
        "# Exam on Artificial Neural Networks (ANN)\n",
        "\n",
        "Welcome the Artificial Neural Networks (ANN) practical exam. In this exam, you will work on a classification task to predict the outcome of incidents involving buses. You are provided with a dataset that records breakdowns and delays in bus operations. Your task is to build, train, and evaluate an ANN model.\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset Overview\n",
        "\n",
        "### **Dataset:**\n",
        "* Just run the command under the `Load Data` section to get the data downloaded and unzipped or you can access it [here](www.kaggle.com/datasets/khaledzsa/bus-breakdown-and-delays)\n",
        "\n",
        "### **Dataset Name:** Bus Breakdown and Delays\n",
        "\n",
        "### **Description:**  \n",
        "The dataset contains records of incidents involving buses that were either running late or experienced a breakdown. Your task is to predict whether the bus was delayed or had a breakdown based on the features provided.\n",
        "\n",
        "### **Features:**\n",
        "The dataset contains the following columns:\n",
        "\n",
        "- `School_Year`\n",
        "- `Busbreakdown_ID`\n",
        "- `Run_Type`\n",
        "- `Bus_No`\n",
        "- `Route_Number`\n",
        "- `Reason`\n",
        "- `Schools_Serviced`\n",
        "- `Occurred_On`\n",
        "- `Created_On`\n",
        "- `Boro`\n",
        "- `Bus_Company_Name`\n",
        "- `How_Long_Delayed`\n",
        "- `Number_Of_Students_On_The_Bus`\n",
        "- `Has_Contractor_Notified_Schools`\n",
        "- `Has_Contractor_Notified_Parents`\n",
        "- `Have_You_Alerted_OPT`\n",
        "- `Informed_On`\n",
        "- `Incident_Number`\n",
        "- `Last_Updated_On`\n",
        "- `Breakdown_or_Running_Late` (Target Column)\n",
        "- `School_Age_or_PreK`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c2b014b",
      "metadata": {
        "id": "4c2b014b"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ad02f5",
      "metadata": {
        "id": "98ad02f5"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d khaledzsa/bus-breakdown-and-delays\n",
        "!unzip bus-breakdown-and-delays.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e39620c",
      "metadata": {
        "id": "3e39620c"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "wn5y8uQ-DmN3"
      },
      "id": "wn5y8uQ-DmN3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "71ccd4e2",
      "metadata": {
        "id": "71ccd4e2"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "This could include:\n",
        "* **Inspect the dataset**\n",
        "\n",
        "* **Dataset structure**\n",
        "\n",
        "* **Summary statistics**\n",
        "\n",
        "* **Check for missing values**\n",
        "\n",
        "* **Distribution of features**\n",
        "\n",
        "* **Categorical feature analysis**\n",
        "\n",
        "* **Correlation matrix**\n",
        "\n",
        "* **Outlier detection**\n",
        "\n",
        "And add more as needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b800b0c",
      "metadata": {
        "id": "0b800b0c"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Bus_Breakdown_and_Delays.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "bo_3DTCjD8oe"
      },
      "id": "bo_3DTCjD8oe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "Kb4oxEZFD4li"
      },
      "id": "Kb4oxEZFD4li",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "lLtumCH6D_8l"
      },
      "id": "lLtumCH6D_8l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "v5hR3P66FTh1"
      },
      "id": "v5hR3P66FTh1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns :\n",
        "  print(f'column {col} :')\n",
        "  print(df[col].unique())\n",
        "  print('-'*100)"
      ],
      "metadata": {
        "id": "FAvr1u0nGimb"
      },
      "id": "FAvr1u0nGimb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How_Long_Delayed_Minutes should be int not an object\n",
        "df['How_Long_Delayed_Minutes'] = df['How_Long_Delayed'].str.extract('(\\d+)').astype(float)\n",
        "df['How_Long_Delayed_Minutes'].fillna(df['How_Long_Delayed_Minutes'].mean(), inplace=True)\n",
        "df['How_Long_Delayed_Minutes'] = df['How_Long_Delayed_Minutes'].astype(int)"
      ],
      "metadata": {
        "id": "f6rW5rOwKcko"
      },
      "id": "f6rW5rOwKcko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "cABosedxKhDu"
      },
      "id": "cABosedxKhDu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['School_Year', 'Run_Type', 'Route_Number', 'Reason', 'Boro', 'Bus_No', 'Bus_Company_Name',\n",
        "                     'How_Long_Delayed', 'Number_Of_Students_On_The_Bus', 'Has_Contractor_Notified_Schools',\n",
        "                     'Has_Contractor_Notified_Parents', 'Have_You_Alerted_OPT',\n",
        "                     'Incident_Number', 'Last_Updated_On']"
      ],
      "metadata": {
        "id": "3MmKfEq0Flnl"
      },
      "id": "3MmKfEq0Flnl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# lets see if there is relation if the more student in the bus could cause accedint\n",
        "\n",
        "corr_matrix = df[['Busbreakdown_ID','Number_Of_Students_On_The_Bus',]].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jEcGnAaGFpfu"
      },
      "id": "jEcGnAaGFpfu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "def remove_outliers_all_columns(df):\n",
        "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "    for col in numeric_cols:\n",
        "        df = remove_outliers(df, col)\n",
        "    return df"
      ],
      "metadata": {
        "id": "NLz2XKUbFXMW"
      },
      "id": "NLz2XKUbFXMW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1a559e40",
      "metadata": {
        "id": "1a559e40"
      },
      "source": [
        "## Data Preprocessing\n",
        "This could include:\n",
        "\n",
        "* **Handle Missing Values**\n",
        "    * Impute missing values or drop them.\n",
        "\n",
        "* **Encode Categorical Variables**\n",
        "    * One-hot encoding\n",
        "    * Label encoding\n",
        "\n",
        "* **Scale and Normalize Data**\n",
        "    * Standardization (Z-score)\n",
        "    * Min-Max scaling\n",
        "\n",
        "* **Feature Engineering**\n",
        "    * Create new features\n",
        "    * Feature selection\n",
        "\n",
        "* **Handle Imbalanced Data**\n",
        "    * Oversampling\n",
        "    * Undersampling\n",
        "\n",
        "* **Handle Outliers**\n",
        "    * Remove outliers\n",
        "    * Transform outliers\n",
        "\n",
        "* **Remove Duplicates**\n",
        "    * Remove redundant or duplicate data\n",
        "\n",
        "\n",
        "And add more as needed!\n",
        "\n",
        "Please treat these as suggestions. Feel free to use your judgment for the rest."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Run_Type'].fillna(df['Run_Type'].mode()[0], inplace=True)\n",
        "df['Route_Number'].fillna(df['Route_Number'].mode()[0], inplace=True)\n",
        "df['Reason'].fillna(df['Reason'].mode()[0], inplace=True)\n",
        "df['Boro'].fillna(df['Boro'].mode()[0], inplace=True)\n",
        "df['How_Long_Delayed'].fillna(df['How_Long_Delayed'].mode()[0], inplace=True)\n",
        "df['Incident_Number'].fillna(df['Incident_Number'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "0_cr28tvOKhd"
      },
      "id": "0_cr28tvOKhd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "H2sfl2GIiyyJ"
      },
      "id": "H2sfl2GIiyyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "G_7xjlVOlEH-"
      },
      "id": "G_7xjlVOlEH-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "for column in categorical_columns:\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "nF5m1H4GzlN4"
      },
      "id": "nF5m1H4GzlN4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "ESJjoVIi0M2V"
      },
      "id": "ESJjoVIi0M2V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bc887660",
      "metadata": {
        "id": "bc887660"
      },
      "source": [
        "## Split the Dataset\n",
        "Next, split the dataset into training, validation, and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Breakdown_or_Running_Late', axis=1)\n",
        "y = df['Breakdown_or_Running_Late']"
      ],
      "metadata": {
        "id": "PRg9LMFYOk6d"
      },
      "id": "PRg9LMFYOk6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "kk4kdLSfmof6"
      },
      "id": "kk4kdLSfmof6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_distribution = y.value_counts()\n",
        "print(class_distribution)\n"
      ],
      "metadata": {
        "id": "UHM7ghCIoI_B"
      },
      "id": "UHM7ghCIoI_B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "FSIIfYQHpkof"
      },
      "id": "FSIIfYQHpkof",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_distribution_resampled = y_train_resampled.value_counts()\n",
        "print(class_distribution_resampled)"
      ],
      "metadata": {
        "id": "F7kRR43BsnnF"
      },
      "id": "F7kRR43BsnnF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "467OFrB_rngi"
      },
      "id": "467OFrB_rngi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ac5e52e1",
      "metadata": {
        "id": "ac5e52e1"
      },
      "source": [
        "## Compile the Model\n",
        "Compile the ANN model by defining the optimizer, loss function, and evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "BmJJIWT0s4NS"
      },
      "id": "BmJJIWT0s4NS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab363be3",
      "metadata": {
        "id": "ab363be3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),loss=BinaryCrossentropy(),metrics=[Accuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a72223",
      "metadata": {
        "id": "e9a72223"
      },
      "source": [
        "## Training the Model\n",
        "Train the ANN model using the training data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, y_train_resampled, validation_data=(X_test_scaled, y_test), epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptCmCP2stsHy",
        "outputId": "0145db6d-ebd9-4248-9190-8cc00430629e"
      },
      "id": "ptCmCP2stsHy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1722/4905\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.2237 - loss: 0.0729"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20ce9661",
      "metadata": {
        "id": "20ce9661"
      },
      "source": [
        "## Evaluate the Model\n",
        "Evaluate the performance of the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print('Accuracy: {}'.format(accuracy))"
      ],
      "metadata": {
        "id": "1Qt3Rg3919dD"
      },
      "id": "1Qt3Rg3919dD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "08e9bc87",
      "metadata": {
        "id": "08e9bc87"
      },
      "source": [
        "## Make Predictions\n",
        "Use the trained model to make predictions on new or unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940fa394",
      "metadata": {
        "id": "940fa394"
      },
      "outputs": [],
      "source": [
        "\n",
        "new_data_scaled = scaler.transform(X_test_scaled)\n",
        "\n",
        "predictions = model.predict(new_data_scaled)\n",
        "\n",
        "\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "print(binary_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94942463",
      "metadata": {
        "id": "94942463"
      },
      "source": [
        "## Model Performance Visualization\n",
        "Visualize the performance metrics such as accuracy and loss over the epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1955952",
      "metadata": {
        "id": "b1955952"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1d32965f",
      "metadata": {
        "id": "1d32965f"
      },
      "source": [
        "## Save the Model\n",
        "Save the trained model for submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e1f00e",
      "metadata": {
        "id": "a4e1f00e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9ebe9b8d",
      "metadata": {
        "id": "9ebe9b8d"
      },
      "source": [
        "## Project Questions:\n",
        "\n",
        "1. **Data Preprocessing**: Explain why you chose your specific data preprocessing techniques (e.g., normalization, encoding). How did these techniques help prepare the data for training the model?\n",
        "2. **Model Architecture**: Describe the reasoning behind your model’s architecture (e.g., the number of layers, type of layers, number of neurons, and activation functions). Why did you believe this architecture was appropriate for the problem at hand?\n",
        "3. **Training Process**: Discuss why you chose your batch size, number of epochs, and optimizer. How did these choices affect the training process? Did you experiment with different values, and what were the outcomes?\n",
        "4. **Loss Function and Metrics**: Why did you choose the specific loss function and evaluation metrics? How do they align with the objective of the task (e.g., regression vs classification)?\n",
        "5. **Regularization Techniques**: If you used regularization techniques such as dropout or weight decay, explain why you implemented them and how they influenced the model's performance.\n",
        "6. **Model Evaluation**: Justify your approach to evaluating the model. Why did you choose the specific performance metrics, and how do they reflect the model's success in solving the task?\n",
        "7. **Model Tuning (If Done)**: Describe any tuning you performed (e.g., hyperparameter tuning) and why you felt it was necessary. How did these adjustments improve model performance?\n",
        "8. **Overfitting and Underfitting**: Analyze whether the model encountered any overfitting or underfitting during training. What strategies could you implement to mitigate these issues?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization: MinMaxScaler was used to scale the features between 0 and 1, ensuring that all input features are on the same scale, which helps in faster convergence during training.\n",
        "Label Encoding: Categorical features were label-encoded to convert them into numerical values, making them suitable for input into the neural network.\n",
        "Model Architecture\n",
        "Number of Layers and Neurons: The architecture includes 3 hidden layers with 64, 32, and 16 neurons, respectively, to capture complex patterns without overcomplicating the model.\n",
        "Activation Functions: ReLU was chosen for hidden layers to introduce non-linearity, while sigmoid was used in the output layer for binary classification.\n",
        "Training Process\n",
        "Batch Size: A batch size of 32 was selected as a balance between memory efficiency and gradient accuracy.\n",
        "Epochs: 20 epochs were used to allow sufficient learning while minimizing overfitting.\n",
        "Optimizer: Adam was chosen for its adaptive learning rate and efficient handling of sparse gradients, leading to faster convergence.\n",
        "Loss Function and Metrics\n",
        "Loss Function: Binary Crossentropy was selected because it is ideal for binary classification tasks, effectively penalizing incorrect predictions.\n",
        "Metrics: Accuracy was used to measure how often the model’s predictions are correct, directly reflecting the goal of classifying breakdowns vs. delays.\n",
        "Regularization Techniques\n",
        "Early Stopping: Early stopping was implemented to prevent overfitting by halting training when the validation loss stopped improving, ensuring the model generalizes well.\n",
        "Model Evaluation\n",
        "Performance Metrics: Accuracy was the primary metric as the objective was to correctly classify the bus incidents. It directly measures the model's effectiveness in this binary classification task."
      ],
      "metadata": {
        "id": "sxn142_V2ZuP"
      },
      "id": "sxn142_V2ZuP"
    },
    {
      "cell_type": "markdown",
      "id": "5f524a61",
      "metadata": {
        "id": "5f524a61"
      },
      "source": [
        "### Answer Here:"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}